Junior Data Scientist Integrated Project
This repository contains my submission for an integrated project designed to demonstrate my foundational understanding of the data science lifecycle. The project includes a theoretical essay, a hands-on data analysis case study, and a report on a relevant professional role.

Essay Insight: "Data Science is the New Electricity"
My essay, "Why Data Science is the New Electricity," argues that data science has become a fundamental, indispensable utility that powers modern innovation across industries. Just as electricity transformed society by providing a universal power source, data science provides the framework for extracting value from the massive amounts of data we now generate. The essay traces the evolution of the field from early statistical analysis and data mining to the "Big Data" era and highlights its transformative impact in three key areas: personalized medicine and diagnostics in healthcare, real-time fraud detection in finance, and optimized public services and targeted campaigns in marketing and government.

Dataset Analysis: Heart Disease Dataset ‚ù§Ô∏è
For the hands-on analysis, I used a public Heart Disease dataset from Kaggle. My analysis, conducted in both Python and R, revealed key insights into the dataset's structure and characteristics.

Python Analysis (Jupyter Notebook):

I identified and counted any missing values within the dataset to ensure data quality before analysis.

I computed and displayed the top 3 correlations between features, identifying strong relationships between a person's age and their maximum heart rate achieved, among other factors.

A histogram was plotted to visualize the distribution of one of the key numerical features, providing a quick understanding of the data's spread.

R Analysis (RStudio Script):

I calculated the mean, median, and variance for a selected numeric column, giving a statistical summary of the central tendency and dispersion.

A ggplot bar chart was created to visually represent the counts of a categorical variable, providing a clear overview of the data's composition.

Chosen Role: Data Engineer üõ†Ô∏è
I chose to explore the role of a Data Engineer. The report in this submission explains that a Data Engineer acts as the architect of data infrastructure, building and maintaining the pipelines that ensure data is clean, reliable, and available for data scientists and analysts. The report details core responsibilities, essential skills, and the key tools of the trade, such as Python, SQL, Apache Spark, and cloud platforms like AWS. It also analyzes a hypothetical LinkedIn job post to highlight five essential requirements for this role:

Proficiency in Python and SQL.

Experience with ETL/ELT pipeline design.

Familiarity with cloud data warehousing solutions.

Hands-on experience with Apache Spark.

A strong understanding of data modeling.
